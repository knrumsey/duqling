---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = FALSE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
library(knitr)
```

# duqling: A Package for Reproducible UQ Research

[![License: GPL
v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![](https://img.shields.io/badge/release%20version-2.1.0-blue.svg)](https://github.com/knrumsey/duqling)


```{r, eval=TRUE, echo=FALSE, fig.cap="", out.width='50%'}
knitr::include_graphics("inst/logos/DUQLING.png")
```


### Description 

The `duqling` R package contains a wide variety of test functions for UQ. The goal of `duqling` is to facilitate reproducible UQ research by providing a large number of test functions, datasets, and automated simulation studies. The main functionality of `duqling` includes.

   1. A large library of test functions (see `quack()` function) with consistent usage and (optional) internal scaling which allows for inputs to be generated on the unit hyper-rectangle.
   2. A large library of UQ datasets (see `data_quack()` function) which are stored in the affiliated [UQDataverse](https://dataverse.harvard.edu/dataverse/UQdataverse/).
   3. Automated simulation studies for emulation (see `run_sim_study()` for test functions and `run_sim_study_data()` for datasets) which internally generates unique random seeds, allowing for direct comparison of results across papers and time. 


## Installation

To install the `duqling` package, type

```{R, eval=FALSE}
# install.packages("devtools")
devtools::install_github("knrumsey/duqling")
library(duqling)
```

## Functions Included in Test Library

A master list of all functions found in the `duqling` package can be found with the command
```{R, eval=TRUE}
duqling::quack()
```

A list of all functions meeting certain criterion can be found with the command
```{R, eval=TRUE}
duqling::quack(input_dim=4:7, stochastic="n")
```

A detailed description of each function (the `borehole()` function, for example) can be found with the command
```{R, eval=TRUE}
duqling::quack("borehole")

```

## Using The Package

Every function in the `duqling` package will (optionally) perform internal scaling so that inputs can be passed on a $(0, 1)$ scale for simplicity. This internal scaling is turned on by setting the argument `scale01=TRUE`. See help files for each individual function for details. 

```{R}
n <- 100
p <- 8
X <- matrix(runif(n*p), nrow=n, ncol=p)

# This is how duqling functions are generally called
y <- duqling::duq(X, "borehole")

# Or equivalently
y <- apply(X, 1, duqling::borehole, scale01=TRUE) 
```

## Reproducible Simulation Studies

To execute a reproducible simulation study, simply write two functions `my_fit()` and `my_pred()` (or lump them both into one function) and call the `run_sim_study()` function with your desired settings. Here's an example using the `BASS` package. 

If both `my_fit()` and `my_pred()` are given, the package will time these steps separately. 
```{R, eval=FALSE}
library(BASS)
#' This function should take arguments
#'    X_train
#'    y_train 
#' and return a fitted model
my_fit <- function(X, y){
  bass(X, y, h1=4, h2=40/nrow(X), verbose=FALSE)
}
```

The value returned by the `my_pred()` function depends on whether interval estimation is desired. If so, `interval = TRUE`, then the function should return a matrix with three columns representing (1) point predictions (2) lower bound of interval estimate and (3) upper bound of interval estimate. If `interval = FALSE`, then the function can return only the first column (or a numeric vector). 

```{R, eval=FALSE}
#' This function should take arguments
#'    fitted_obj
#'    X_test
#'    conf_level (only if interval = TRUE) 
#' and return a matrix of predictions (see above for details)
my_pred <- function(obj, X_test, conf_level=0.95){
  alpha <- 1 - conf_level
  preds <- predict(obj, Xt)
  
  # Get point prediction
  yhat <- apply(preds, 2, mean)
  
  # Get uncertainty
  sd <- sqrt(apply(preds, 2, var) + mean(obj$s2)) 
  
  # Make matrix to be returned
  res <- cbind(yhat,          # Point estimate
               yhat - 2*sd,   # Lower bound
               yhat + 2*sd)   # Upper bound
  
  return(res)
}
```

Alternatively, everything can be lumped into the `my_fit()` function, but only the total time (for fitting and prediction) will be computed. Here's an example with the `BART` package. 

```{R, eval =FALSE}
library(BART)
my_fit <- function(X_train, y_train, X_test, conf_level=0.95){
  mod <- wbart(X_train, y_train, X_test)
  yhat <- mod$yhat.test
  sd_post_mean <- apply(mod$yhat.test, 2, sd)
  sd_post_eps  <- mean(mod$sigma)
  sd <- sqrt(sd_post_mean^2 + sd_post_eps^2)
  cbind(yhat,
        yhat - 2*sd,
        yhat + 2*sd)
}

my_pred <- NULL
```

## Simulation Study Settings
When `run_sim_study` is called, each combination of the following arguments will be run for `replications` replications.

   - `fnames`: a vector of functions to test on. Should be a subset of `quack(input_cat=FALSE, stochastic="n", response_type="uni")$fname`.
   - `n_train`: a vector of sample sizes.
   - `NSR`: Noise to Signal ratio. The inverse of the more-standard SNR. 
   - `design_type`: What type of designs should be generated. Options are "LHS" (maximin when $n\leq 2000$, random otherwise), "grid" and "uniform". 
   
   
An example call would be
```{R, eval=FALSE}
results <- run_sim_study(my_fit, my_pred,
                         fnames = c("dms_additive", "borehole", "welch20"),
                         interval = TRUE,
                         n_train = c(100, 500),
                         NSR = c(0, 1/5),
                         design_type = "LHS",
                         method_names <- c("my_method"),
                         replications = 5)
```

Some suggested function vectors for simulation studies are included in the functions

```{R, eval=FALSE}
get_sim_functions_full()     #51 functions
get_sim_functions_medium()   #20 functions
get_sim_functions_short()    #10 functions
get_sim_functions_tiny()     #4  functions
get_sim_functions_2d()       #12 functions
```


## Datasets and duqling

All data sets are hosted at our affiliated [UQDataverse](https://dataverse.harvard.edu/dataverse/UQdataverse/). For a full list of the unprocessed datasets, type
```{R, eval=TRUE}
duqling::data_quack(raw=TRUE)
```

Some datasets have been processed for univariate emulation. These can be found with the command
```{R, eval=TRUE}
duqling::data_quack()
```

Raw datasets can be read (via the internet) with the function `get_UQ_data()` and the processed data with the function `get_emulation_data()`. For example,
```{R, eval=FALSE}
data <- duqling::get_UQ_data("strontium_plume")

data <- duqling::get_emulation_data("strontium_plume_p4b")
X <- data$X
y <- data$y
```

Akin to the `run_sim_study()` function, automated simulation studies can be run with cross-validation using the datasets in duqling. See the previous section on simulation studies for details. 
```{R, eval=FALSE}
results <- run_sim_study_data(my_fit, my_pred,
                dnames=c("pbx9501_gold", "strontium_plume_p104"),
                folds=c(5, 10))
```

##  Analysis and visualization

The `duqling` package provides many tools for analyzing emulator results and generating publication-ready figures. An example analysis proceeds as follows:

```{R, eval=FALSE}
# Process your sim study results from before
duq_obj <- process_sim_study(results)

# Load in data from the big simulation study (Rumsey et al 2025; coming soon)
load("data/existing_results.Rda") # --> results_paper

# Now you can join your results together!
duq_obj <- join_sim_study(duq_obj,
                          process_sim_study(results_paper))

# Filter down to just the results you want
duq_obj_sub <- filter_sim_study(duq_obj, 
                                id = c("dms_additive", "borehole", "welch20"),
                                n_train = 500,
                                NSR = 0,
                                method = c("my_method", "gp", "bnn", "confrf"))

# Now you can make plots and summaries!
summarize_sim_study(duq_obj_sub, summarize = c("time", "CRPS"))
rankplot_sim_study(duq_obj_sub, "RMSE")
heatmap_sim_study(duq_obj_sub, "CRPS")
paretoplot_sim_study(duq_obj_sub, c("CRPS_rel", "time_rel_log"))

# View boxplots
boxplots_sim_study(filter_sim_study(duq_obj_sub, id="borehole"), "CRPS_norm")
```




### Release Information

LA-UR-25-27410

### Copyright Notice

*2023. Triad National Security, LLC. All rights reserved.*

*This program was produced under U.S. Government contract 89233218CNA000001 for Los Alamos National Laboratory (LANL), which is operated by Triad National Security, LLC for the U.S. Department of Energy/National Nuclear Security Administration. All rights in the program are. reserved by Triad National Security, LLC, and the U.S. Department of Energy/National Nuclear Security Administration. The Government is granted for itself and others acting on its behalf a nonexclusive, paid-up, irrevocable worldwide license in this material to reproduce, prepare. derivative works, distribute copies to the public, perform publicly and display publicly, and to permit others to do so.*




