% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_sim_study.R
\name{run_sim_study}
\alias{run_sim_study}
\title{Reproducible Simulation Study (Test Functions)}
\usage{
run_sim_study(
  fit_func,
  pred_func = NULL,
  fnames = NULL,
  conf_level = c(0.8, 0.9, 0.95, 0.99),
  score = TRUE,
  n_train = 100,
  n_test = 1000,
  NSR = 0,
  design_type = "LHS",
  replications = 1,
  seed = 42,
  method_names = NULL,
  mc_cores = 1,
  fallback_on_error = TRUE,
  print_error = FALSE,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{fit_func}{If \code{pred_func} is specified, the \code{fit_func} should take two arguments called \code{X_train} and \code{y_train}, and should return an object which will be passed to \code{pred_func}. If \code{pred_func} is NOT specified, then \code{fit_func} should take a third argument called \code{X_test}, and should return predictive samples (see pred_func documentation).}

\item{pred_func}{A function taking two arguments: (i) the object returned by \code{fit_func} and a matrix \code{X_test}. The function should return an matrix of samples from the predictive distribution, with one column per test point. For additional flexibility, see the details below.}

\item{fnames}{A vector of function names from the \code{duqling} package. See \code{quack()} for details.}

\item{conf_level}{A vector of confidence levels. For computing coverages and interval scores.}

\item{score}{Logical. Should CRPS be computed?}

\item{n_train}{the sample size (or vector of sample sizes) for each training set}

\item{n_test}{the sample size for each testing set}

\item{NSR}{the noise to signal ratio (inverse of the more-standard signal to noise ratio).}

\item{design_type}{How should the training and testing designs be generated? Options are \code{"LHS"}, \code{"grid"}, \code{"random"}, or \code{"custom"}. See details for information on custom designs.}

\item{replications}{The replications to run. Can be a single integer \code{r} (runs replications 1 to r), a vector of integers (runs only those specific replications), or a single negative integer \code{-k} (runs only replication k).}

\item{seed}{Seed for random number generators. For reproducibility, we discourage the use of this argument.}

\item{method_names}{A vector of method names, length equal to \code{length(fit_func)}. If NULL, the indexed names \code{my_method<i>} will be used.}

\item{mc_cores}{How many cores to use for parallelization over replications.}

\item{fallback_on_error}{When \code{TRUE} (default), we use a null model (\code{N(mean(y_train), sd(y_train))}) for robustness if a failure is detected in either \code{fit_func} or \code{pred_func}.}

\item{print_error}{Logical (default FALSE). Should error messages (from \code{fit_func} or \code{pred_func})be printed?}

\item{verbose}{should progress be reported?}

\item{...}{Additional arguments for advance (custom) usage. See vignette for details.}
}
\value{
A data frame where each row corresponds to the results of a single simulation scenario, replication index, and method. The columns include:
  \itemize{
    \item \code{method}: Name of the fitted method, if provided. Unique names (\code{method<indx>}) names are assigned otherwise.
    \item \code{fname}: The test function name from \code{duqling::quack()$fname}. See details for custom functions.
    \item \code{input_dim}: Input dimension of the test function.
    \item \code{n}: Number of training points.
    \item \code{NSR}: Noise-to-signal ratio used in data generation.
    \item \code{design_type}: Type of experimental design used for data generation ("LHS", "grid", or "random").
    \item \code{rep}: Replication index.
    \item \code{t_fit}: Elapsed time (seconds) for model fitting (if applicable).
    \item \code{t_pred}: Elapsed time (seconds) for model prediction (if applicable).
    \item \code{t_tot}: Total elapsed time for fitting and prediction.
    \item \code{failure_type}: Indicates if the method failed at "fit", "pred", or "none" (if no failure).
    \item \code{RMSE}: Root mean squared error on the test set.
    \item \code{FVU}: Fraction of variance unexplained (RMSE\(^2\) divided by total variance).
    \item \code{COVER<level>}: Coverage rates for each specified confidence level (e.g., \code{COVER0.8}, \code{COVER0.9}, etc.).
    \item \code{MIS<level>}: Mean interval scores for each specified confidence level.
    \item \code{CRPS}: Mean continuous ranked probability score (CRPS) on the test set.
    \item \code{CRPS_min}, \code{CRPS_Q1}, \code{CRPS_med}, \code{CRPS_Q3}, \code{CRPS_max}: Summary statistics (minimum, first quartile, median, third quartile, maximum) for the CRPS distribution over the test set.
  }
Additional columns may be included for other metrics or settings depending on options provided.
}
\description{
Reproducible code for simulation studies.
}
\details{
Code to conduct a reproducible simulation study to compare emulators. By reporting the parameters to the study, other authors can compare their results directly.
Only \code{fit_func} needs to be specified, but only the total time will be reported. The simplest (and recommended) approach is that the \code{fit_func} (or \code{pred_func}) should return a matrix of posterior samples, with one column per test point (e.g., per row in \code{X_test}). Any number of rows (predictive samples) is allowed. In this case, the mean of the samples is used as a prediction and the R \code{quantile} function is used to construct confidence intervals. This default behavior can be changed by instead allowing \code{fit_func} (or \code{pred_func}) to return a named list with fields i) \code{samples} (required), ii) \code{preds} (optional; a vector of predictions), and iii) intervals (optional; a 2 by n by k array of interval bounds where n is the number of test points and k is \code{length(conf_level)}).
}
\section{Custom functions and designs}{


Advanced users can extend \code{run_sim_study()} with their own test
functions or design types without modifying the package code.

\emph{Custom functions:}

- To supply a custom test function, create a list with fields:

  - \code{$func}: a function with signature \code{f(x, scale01)} that returns
    a scalar. Here \code{x} is a numeric vector of length \code{p}, and
    \code{scale01} is a logical flag indicating whether inputs have been
    scaled to \eqn{[0,1]^p}.

  - \code{$input_dim}: an integer specifying the input dimension \code{p}.

- Pass this list as an extra argument to \code{run_sim_study()} with an
arbitrary name, e.g.
\preformatted{
  f <- function(x, scale01=TRUE) x[1] - x[2]^2
  my_list <- list(func = f, input_dim = 5)
  run_sim_study(fit_func, pred_func, fnames = "custom_foobar", foobar = my_list)
}

- Inside \code{fnames}, use the string \code{"custom_<name>"} to refer to
your custom function (here, \code{"custom_foobar"}).

\emph{Custom designs:}
- The \code{design_type} argument may also be set to \code{"custom"}.

- In this case, you must supply an additional argument \code{design_func}
  (through \code{...}), which should be a function of \code{n} and \code{p}
  returning an \eqn{n \times p} design matrix.

- Example:
\preformatted{
  correlated_design <- function(n, p) {
    d <- lhs::randomLHS(n, p)
    d[,1] <- (d[,2] + d[,3]) / 2
    d
  }
  run_sim_study(fit_func, pred_func,
                fnames = "ishigami",
                design_type = "custom",
                design_func = correlated_design)
}
}

\examples{

# METHOD 1: Linear Regression
lm_fit <- function(X, y){
  Xdf <- as.data.frame(X)
  colnames(Xdf) <- paste0("X", seq_len(ncol(X)))
  lm(y ~ ., data = Xdf)
}
lm_pred <- function(obj, Xt){
  Xt_df <- as.data.frame(Xt)
  colnames(Xt_df) <- paste0("X", seq_len(ncol(Xt_df)))
  mean_pred <- predict(obj, Xt_df)
  sigma_est <- sd(residuals(obj))
  nt <- nrow(Xt_df)
  preds <- replicate(1000, mean_pred + rnorm(nt, 0, sigma_est))
}

# METHOD 2: Projection Pursuit
ppr_fit <- function(X, y){
  ppr(X, y, nterms=3)
}
ppr_pred <- function(obj, Xt){
  nt <- nrow(Xt)
  mean_pred <- predict(obj, data.frame(Xt))
  sigma_est <- sd(residuals(obj))
  preds <- replicate(1000, mean_pred + rnorm(nt, 0, sigma_est))
}

my_fit  <- list(lm_fit, ppr_fit)
my_pred <- list(lm_pred, ppr_pred)
run_sim_study(my_fit, my_pred,
             fnames=c("dms_additive", "borehole"),
             n_train=50,
             replications=2,
             method_names=c("lm", "ppr") # Optional
             )

}
\references{
Surjanovic, Sonja, and Derek Bingham. "Virtual library of simulation experiments: test functions and datasets." Simon Fraser University, Burnaby, BC, Canada, accessed May 13 (2013): 2015.
}
